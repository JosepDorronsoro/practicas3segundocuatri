{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dd665361-06ac-43c6-b099-1691f9649acc",
   "metadata": {},
   "source": [
    "## Inroduction to Probabilistic Machine Learning  \n",
    "\n",
    "Family name:\n",
    "\n",
    "Name:\n",
    "\n",
    "Date: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4407b878-2cdd-4665-9784-37ea079e97fb",
   "metadata": {},
   "source": [
    "### The exponential distribution\n",
    "Given an exponential random variable whose pdf is\n",
    "$$\n",
    "\\text{exp\\_pdf}\\left(x, \\lambda \\right) = \\frac{1}{Z(\\lambda)} \\exp\\left(- \\lambda x \\right)\n",
    "$$\n",
    "\n",
    "[TODO] Derive using markdown + latex:\n",
    "1. The normalization constant $ Z(\\lambda)$\n",
    "\n",
    "Para normalizar la exp_pdf deberíamos tener en cuenta que \n",
    "\n",
    "$$ \\int_{- \\infty}^{\\infty} dx \\ \\text{exp\\_pdf}(x;\\lambda) = 1 $$\n",
    "\n",
    "Y por la propia definción de la función tenemos que:\n",
    "\n",
    "$$ \\frac{1}{Z(\\lambda)}\\int_{0}^{\\infty} dx \\exp(-\\lambda x) = 1 \\to \\frac{1}{-\\lambda Z(\\lambda)} \\int_{0}^{\\infty} dx -\\lambda \\exp(-\\lambda x) = $$\n",
    "\n",
    "$$ = \\frac{1}{-\\lambda Z(\\lambda)} [\\exp(-\\lambda x)]_{0}^{\\infty} =  \\frac{1}{-\\lambda Z(\\lambda)} (0-1) = 1 \\to Z(\\lambda) = \\frac{1}{\\lambda}$$\n",
    "\n",
    "Y por tanto, la pdf quedaría tal que:\n",
    "\n",
    "$$\n",
    "\\text{exp\\_pdf}\\left(X, \\lambda \\right) = \\lambda \\exp\\left(- \\lambda x \\right)\n",
    "$$\n",
    "\n",
    "2. The cdf\n",
    "\n",
    "$$\n",
    "\n",
    "\\text{exp\\_cdf}(X) = \\int_{-\\infty}^x dx' \\text{exp\\_pdf}(x') = \\int_{-\\infty}^x dx' \\lambda \\exp(-\\lambda x') = 1 - \\exp(-\\lambda x)\n",
    "\n",
    "\n",
    "$$\n",
    "\n",
    "3. The inverse cdf\n",
    "\n",
    "$$\n",
    "\n",
    "y = 1- \\exp(-\\lambda x) \\to \\exp(-\\lambda x) = y-1 \\to x = \\frac{1}{-\\lambda} \\log(y-1)\n",
    "\n",
    "$$\n",
    "\n",
    "Luego la inversa de la cdf será:\n",
    "\n",
    "$$\n",
    "\n",
    "\\text{exp\\_cdf}^{-1}(x) = \\frac{1}{-\\lambda} \\log(x-1)\n",
    "\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf39eefc-7146-4f9a-b89b-cbe06f605644",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from from tools import exp_distribution, probabilistic_fit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f258a3-5c84-406c-b7b2-555509703784",
   "metadata": {},
   "source": [
    "Para generar números aleatorios que se distribuyan según la exponencial, el método del inverso es muy útil. La idea es la siguiente:\n",
    "\n",
    "La función $CDF$ devuelve la probabilidad (en el intervalo $[0, 1]$) de que una variable aleatoria $X$ tome un valor concreto $x$: \n",
    "\n",
    "$$\n",
    "\n",
    "\\text{exp\\_cdf}: \\mathbb{R} \\to [0,1]  \\ \\text{tq} \\ \\text{exp\\_cdf}(x) = P(X\\leq x)\n",
    "\n",
    "$$\n",
    "\n",
    "Para coneguir números aleatorios distribuidos según nuestra $\\text{exp\\_pdf}$, la idea a seguir es mapear, utilizando la inversa de $\\text{exp\\_pdf}$, $\\text{exp\\_cdf}^{-1}$, puntos distribuidos uniformemente en el intervalo $[0,1]$ a la $\\text{exp\\_pdf}$. Definimos la $\\text{exp\\_pdf}^{-1}$ tal que:\n",
    "\n",
    "\n",
    "$$\n",
    "\n",
    "\\text{exp\\_cdf}: [0,1] \\to \\mathbb{R}  \\ \\text{tq} \\ \\text{exp\\_cdf}^{-1}(x) = \\frac{1}{-\\lambda} \\log(y-1)\n",
    "\n",
    "$$\n",
    "\n",
    "Dicho con otras palabras: aplicando esta función a cada punto del intervalo original $[0,1]$, distribuido uniformemente, obtendremos un conjunto de puntos de igual tamaño, pero distribuidos de forma exponencial, en lugar de uniforme. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900a773a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [TODO] Generate an iid sample of the exponential distribution using the method of the inverse \n",
    "\n",
    "rng = np.random.default_rng(123)\n",
    "lam_true = 1.5\n",
    "N = 100000\n",
    "\n",
    "# Creamos N números aleatorios distribuidos uniformemente en el intervalo [0, 1):\n",
    "\n",
    "X = rng.random(size=N)\n",
    "\n",
    "# Creamos una función para aplicar a cada valor del array la cdf inversa:\n",
    "\n",
    "vectorize_exp = np.vectorize(exp_distribution.exp_inv)\n",
    "\n",
    "# Creamos un nuevo array para los nuevos valores. Usamos el lambda dado:\n",
    "\n",
    "X_exp = vectorize_exp(X, lam=lam_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79291152-7771-43eb-ad66-c050b222ec05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [TODO] Plot the histogram of the sample and compare with pdf\n",
    "n_bins = np.min(np.sqrt(N), 50)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x_teorico = np.linspace(min(X_exp), max(X_exp), 100)\n",
    "y_teorico = 1.5 * np.exp(-1.5 * x_teorico)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(X_exp, density=True, bins=30, label='Muestreo')\n",
    "plt.xlabel('$X=x$')\n",
    "plt.ylabel('Densidad')\n",
    "plt.title('Histograma del muestreo de valores siguiendo la función de \\n densidad de probabilidad $f(x) = 1.5 e^{-1.5x}$.\\n')\n",
    "plt.plot(x_teorico, y_teorico, color='red', lw=2, label='$f(x) = 1.5 e^{-1.5x}$')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88aa6f8",
   "metadata": {},
   "source": [
    "## Maximum Likelihood estimate of $\\lambda$\n",
    "\n",
    "[TODO] Derive using markdown + latex:\n",
    "1. The expression of the likelihood function for the iid sample $ \\mathcal{D} = \\left\\{X_n \\right\\}_{n=1}^N$\n",
    "2. The value of $\\lambda$ that maximizes the likelihood\n",
    "3. The expression of the posterior assuming the prior for lambda "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba6a152-a03a-47b3-b66a-375f9fdbbc43",
   "metadata": {},
   "source": [
    "#### Solution:\n",
    "The likelihood is\n",
    "$$\n",
    "\\mathcal{L}(\\lambda; \\mathcal{D}) = P\\left( \\mathcal{D}  \\vert \\lambda \\right) \n",
    "= P\\left( \\left\\{X_n \\right\\}_{n=1}^N  \\vert \\lambda \\right) \n",
    "= \\prod_{n=1}^N \\mathrm{exp\\_pdf}\\left( X_n ; \\lambda \\right) \n",
    "= \\prod_{n=1}^N \\left(\\lambda \\exp\\left( - \\lambda X_n \\right)\\right) \n",
    "= \\lambda^N \\exp\\left(-\\lambda \\sum_{n=1}^N X_n\\right).\n",
    "$$\n",
    "\n",
    "The corresponding log-likelihood  is\n",
    "$$\n",
    "\\mathcal{LL}(\\lambda; \\mathcal{D})\n",
    "= \\log \\mathcal{L}(\\lambda; \\mathcal{D})\n",
    "= N \\log \\lambda - \\lambda \\sum_{n=1}^N X_n.\n",
    "$$\n",
    "\n",
    "Taking the derivative of this likelihood with respect to $\\lambda$,\n",
    "$$\n",
    "\\frac{d\\mathcal{LL}(\\lambda; \\mathcal{D})}{d\\lambda}\n",
    "= \\frac{N}{\\lambda} - \\sum_{n=1}^N X_n.\n",
    "$$\n",
    "\n",
    "Setting the derivative equal to zero gives\n",
    "$$\n",
    "\\frac{N}{\\lambda_{ML}^*} - \\sum_{n=1}^N X_n = 0 \n",
    "\\quad \\Longrightarrow \\quad\n",
    "\\frac{N}{\\lambda_{ML}^*} = \\sum_{n=1}^N X_n.\n",
    "$$\n",
    "Hence the maximum likelihood estimator is\n",
    "$$\n",
    "\\lambda_{ML}^* = \\frac{N}{\\sum_{n=1}^N X_n}\n",
    "= \\frac{1}{\\hat{\\mu}_X},\n",
    "$$\n",
    "where\n",
    "$$\n",
    "\\hat{\\mu}_X = \\frac{1}{N}\\sum_{n=1}^N X_n.\n",
    "$$\n",
    "\n",
    "The second derivative,\n",
    "$$\n",
    "\\frac{d^2\\mathcal{LL}(\\lambda; \\mathcal{D})}{d\\lambda^2}\n",
    "= -\\frac{N}{\\lambda^2} < 0,\n",
    "$$\n",
    "is negative, which confirms that this critical point (zero derivative) is a maximum.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c759025e-4793-4b3b-b9b1-4843ee59b84b",
   "metadata": {},
   "source": [
    "### Numerical maximization of the likelikood \n",
    "\n",
    "We shall now use a numerical method to maximize the likelihood and compare with the closed-form solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae66f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [TODO]\n",
    "lam_mle_analytic =   # Closed-form formula derived in previous cell\n",
    "lam_mle_numerical =  # Numerical estimate from optimization\n",
    "\n",
    "print(lam_mle_numerical, lam_exact_analytic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d1aae4-6f3e-4857-b8fd-a61dd9bac734",
   "metadata": {},
   "source": [
    "## MAP estimate of $\\lambda$\n",
    "Assume the conjugate prior\n",
    "$$\n",
    "\\lambda \\sim \\mathrm{Gamma}(\\alpha,\\beta),\n",
    "$$\n",
    "with density\n",
    "$$\n",
    "p(\\lambda) = \\frac{\\beta^\\alpha}{\\Gamma(\\alpha)} \\lambda^{\\alpha-1} e^{-\\beta \\lambda}.\n",
    "$$\n",
    "\n",
    "[TODO] Derive using markdown + latex:\n",
    "1. the expression of the posterior assuming the Gamma prior for $\\lambda$, \n",
    "2. the value of $\\lambda$ that maximizes the posterior.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ff915f-a5b8-49c0-94a1-3bcf661188b4",
   "metadata": {},
   "source": [
    "### Numerical maximization of the posterior \n",
    "\n",
    "We shall now use a numerical method to maximize the posterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53d294d-5b01-4e6d-b21d-4d7f9b5263ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [TODO]\n",
    "alpha = 4.0\n",
    "beta = 0.1\n",
    "lam_map_analytic =   # Closed-form formula derived in previous cell\n",
    "lam_map_numerical =  # Numerical estimate from optimization\n",
    "\n",
    "\n",
    "print(lam_map_analytic, lam_map_numerical)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2f0da5-bd30-490c-9702-fb4747c29b34",
   "metadata": {},
   "source": [
    "### Questions\n",
    "[TODO] Answer these question using markdown + latex:\n",
    "1. What are the values of the mean, the standandard deviation, and the mode of the prior of $\\lambda$?\n",
    "2. How different are the ML and MAP estimates of $\\lambda$?\n",
    "    * When the sample size \\(N = 100\\) are they very different?\n",
    "    * When the sample size \\(N = 1000\\) are they very different?\n",
    "3. What do you conclude from the answers to the previous questions?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c893db8-c544-432a-83a0-f918d836fdef",
   "metadata": {},
   "source": [
    "### Summary and conclusions \n",
    "[TODO] Summary and conclusions of what I have learned using markdown + latex:\n",
    "1. [TODO: as many as necessary]\n",
    "2. Fit a model pdf to an iid sample using the maximum likelihood method.\n",
    "3. [TODO: as many as necessary]\n",
    "4.\n",
    "...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958007c6-66bb-4757-bed3-97c94af49a47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
