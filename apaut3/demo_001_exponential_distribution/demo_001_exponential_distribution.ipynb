{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dd665361-06ac-43c6-b099-1691f9649acc",
   "metadata": {},
   "source": [
    "## Inroduction to Probabilistic Machine Learning  \n",
    "\n",
    "Family name:\n",
    "\n",
    "Name:\n",
    "\n",
    "Date: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4407b878-2cdd-4665-9784-37ea079e97fb",
   "metadata": {},
   "source": [
    "### The exponential distribution\n",
    "Given an exponential random variable whose pdf is\n",
    "$$\n",
    "\\text{exp\\_pdf}\\left(x, \\lambda \\right) = \\frac{1}{Z(\\lambda)} \\exp\\left(- \\lambda x \\right)\n",
    "$$\n",
    "\n",
    "[TODO] Derive using markdown + latex:\n",
    "1. The normalization constant $ Z(\\lambda)$\n",
    "\n",
    "Para normalizar la exp_pdf deberíamos tener en cuenta que \n",
    "\n",
    "$$ \\int_{- \\infty}^{\\infty} dx \\ \\text{exp\\_pdf}(x;\\lambda) = 1 $$\n",
    "\n",
    "Y por la propia definción de la función tenemos que:\n",
    "\n",
    "$$ \\frac{1}{Z(\\lambda)}\\int_{0}^{\\infty} dx \\exp(-\\lambda x) = 1 \\to \\frac{1}{-\\lambda Z(\\lambda)} \\int_{0}^{\\infty} dx -\\lambda \\exp(-\\lambda x) = $$\n",
    "\n",
    "$$ = \\frac{1}{-\\lambda Z(\\lambda)} [\\exp(-\\lambda x)]_{0}^{\\infty} =  \\frac{1}{-\\lambda Z(\\lambda)} (0-1) = 1 \\to Z(\\lambda) = \\frac{1}{\\lambda}$$\n",
    "\n",
    "Y por tanto, la pdf quedaría tal que:\n",
    "\n",
    "$$\n",
    "\\text{exp\\_pdf}\\left(X, \\lambda \\right) = \\lambda \\exp\\left(- \\lambda x \\right)\n",
    "$$\n",
    "\n",
    "2. The cdf\n",
    "\n",
    "$$\n",
    "\n",
    "\\text{exp\\_cdf}(X) = \\int_{-\\infty}^x dx' \\text{exp\\_pdf}(x') = \\int_{-\\infty}^x dx' \\lambda \\exp(-\\lambda x') = 1 - \\exp(-\\lambda x)\n",
    "\n",
    "\n",
    "$$\n",
    "\n",
    "3. The inverse cdf\n",
    "\n",
    "$$\n",
    "\n",
    "y = 1- \\exp(-\\lambda x) \\to \\exp(-\\lambda x) = y-1 \\to x = \\frac{1}{-\\lambda} \\log(y-1)\n",
    "\n",
    "$$\n",
    "\n",
    "Luego la inversa de la cdf será:\n",
    "\n",
    "$$\n",
    "\n",
    "\\text{exp\\_cdf}^{-1}(X) = \\frac{1}{-\\lambda} \\log(y-1)\n",
    "\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf39eefc-7146-4f9a-b89b-cbe06f605644",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tools import exp_distribution, probabilistic_fit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f258a3-5c84-406c-b7b2-555509703784",
   "metadata": {},
   "source": [
    "### Method of the inverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "900a773a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [TODO] Generate an iid sample of the exponential distribution using the method of the inverse \n",
    "\n",
    "rng = np.random.default_rng(123)\n",
    "lam_true = 1.5\n",
    "N = 10000\n",
    "\n",
    "X = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79291152-7771-43eb-ad66-c050b222ec05",
   "metadata": {},
   "outputs": [
    {
     "ename": "AxisError",
     "evalue": "axis 50 is out of bounds for array of dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# [TODO] Plot the sample histogram and compare with pdf\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m n_bins \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mN\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/numpy/core/fromnumeric.py:2953\u001b[0m, in \u001b[0;36mmin\u001b[0;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2836\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_min_dispatcher)\n\u001b[1;32m   2837\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mmin\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue, initial\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue,\n\u001b[1;32m   2838\u001b[0m         where\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue):\n\u001b[1;32m   2839\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2840\u001b[0m \u001b[38;5;124;03m    Return the minimum of an array or minimum along an axis.\u001b[39;00m\n\u001b[1;32m   2841\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2951\u001b[0m \u001b[38;5;124;03m    6\u001b[39;00m\n\u001b[1;32m   2952\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2953\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapreduction\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mminimum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmin\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2954\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/numpy/core/fromnumeric.py:86\u001b[0m, in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m reduction(axis\u001b[38;5;241m=\u001b[39maxis, dtype\u001b[38;5;241m=\u001b[39mdtype, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpasskwargs)\n\u001b[1;32m     85\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 86\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mreduction\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpasskwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ufunc\u001b[38;5;241m.\u001b[39mreduce(obj, axis, dtype, out, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpasskwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/numpy/core/_methods.py:45\u001b[0m, in \u001b[0;36m_amin\u001b[0;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_amin\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     44\u001b[0m           initial\u001b[38;5;241m=\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m---> 45\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mumr_minimum\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mAxisError\u001b[0m: axis 50 is out of bounds for array of dimension 0"
     ]
    }
   ],
   "source": [
    "# [TODO] Plot the sample histogram and compare with pdf\n",
    "n_bins = np.min(np.sqrt(N), 50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88aa6f8",
   "metadata": {},
   "source": [
    "## Maximum Likelihood estimate of lambda\n",
    "\n",
    "[TODO] Derive using markdown + latex:\n",
    "1. The expression of the likelihood function for the iid sample $ \\mathcal{D} = \\left\\{X_n \\right\\}_{n=1}^N$\n",
    "2. The value of $\\lambda$ that maximizes the likelihood\n",
    "3. The expression of the posterior assuming the prior for lambda "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba6a152-a03a-47b3-b66a-375f9fdbbc43",
   "metadata": {},
   "source": [
    "The likelihood is\n",
    "$$\n",
    "L(\\lambda) = \\lambda^N e^{-\\lambda \\sum_{n=1}^N x_n}\n",
    "$$\n",
    "\n",
    "The log-likelihood corresponding is\n",
    "$$\n",
    "\\ell(\\lambda)\n",
    "= \\log L(\\lambda)\n",
    "= N \\log \\lambda - \\lambda \\sum_{n=1}^N x_n.\n",
    "$$\n",
    "\n",
    "Taking the derivative with respect to \\(\\lambda\\),\n",
    "$$\n",
    "\\frac{d\\ell(\\lambda)}{d\\lambda}\n",
    "= \\frac{N}{\\lambda} - \\sum_{n=1}^N x_n.\n",
    "$$\n",
    "\n",
    "Setting the derivative equal to zero gives\n",
    "$$\n",
    "\\frac{N}{\\lambda_{ML}^*} = \\sum_{n=1}^N X_n,\n",
    "$$\n",
    "hence the maximum likelihood estimator is\n",
    "$$\n",
    "\\lambda_{ML}^* = \\frac{N}{\\sum_{n=1}^N x_n}\n",
    "= \\frac{1}{\\mathbb{E}[X]},\n",
    "$$\n",
    "where\n",
    "$$\n",
    "\\mathbb{E}[X] = \\frac{1}{N}\\sum_{n=1}^N X_n.\n",
    "$$\n",
    "\n",
    "The second derivative,\n",
    "$$\n",
    "\\frac{d^2\\ell(\\lambda)}{d\\lambda^2}\n",
    "= -\\frac{N}{\\lambda^2} < 0,\n",
    "$$\n",
    "confirms that this critical point is a maximum.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c759025e-4793-4b3b-b9b1-4843ee59b84b",
   "metadata": {},
   "source": [
    "### Numerical optimization of the likelikood \n",
    "\n",
    "We shall now use a numerical method to optimize the likelihood and compare with the closed-form solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae66f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [TODO]\n",
    "lam_mle_numerical = \n",
    "lam_mle_analytic = \n",
    "\n",
    "print(lam_mle_numerical, lam_exact_analytic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d1aae4-6f3e-4857-b8fd-a61dd9bac734",
   "metadata": {},
   "source": [
    "## MAP estimate of lambda\n",
    "Assume the conjugate prior\n",
    "$$\n",
    "\\lambda \\sim \\mathrm{Gamma}(\\alpha,\\beta),\n",
    "$$\n",
    "with density\n",
    "$$\n",
    "p(\\lambda) = \\frac{\\beta^\\alpha}{\\Gamma(\\alpha)} \\lambda^{\\alpha-1} e^{-\\beta \\lambda}.\n",
    "$$\n",
    "\n",
    "[TODO] Derive using markdown + latex:\n",
    "1. The expression of the posterior assuming the Gamma prior for $\\lambda$. \n",
    "2. The value of $\\lambda$ that maximizes the posterior.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515f7f8f-4293-4709-b184-b5ce2093452a",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Multiplying the prior by the likelihood,\n",
    "$$\n",
    "p(\\lambda \\mid x)\n",
    "\\propto \\lambda^{\\alpha+n-1}\n",
    "\\exp\\!\\left[-\\lambda\\!\\left(\\beta + \\sum_{i=1}^n x_i\\right)\\right].\n",
    "$$\n",
    "Hence,\n",
    "$$\n",
    "\\lambda \\mid x \\sim \\mathrm{Gamma}\\!\\left(\n",
    "\\alpha + n,\\;\n",
    "\\beta + \\sum_{i=1}^n x_i\n",
    "\\right).\n",
    "$$\n",
    "\n",
    "\\paragraph{Posterior predictive distribution.}\n",
    "The posterior predictive density for a new observation $x_{\\mathrm{new}}$ is\n",
    "$$\n",
    "p(x_{\\mathrm{new}} \\mid x)\n",
    "= \\int_0^\\infty p(x_{\\mathrm{new}} \\mid \\lambda)\\, p(\\lambda \\mid x)\\, d\\lambda.\n",
    "$$\n",
    "Substituting,\n",
    "$$\n",
    "p(x_{\\mathrm{new}} \\mid x)\n",
    "= \\int_0^\\infty\n",
    "\\lambda e^{-\\lambda x_{\\mathrm{new}}}\n",
    "\\frac{(\\beta')^{\\alpha'}}{\\Gamma(\\alpha')}\n",
    "\\lambda^{\\alpha'-1} e^{-\\beta' \\lambda}\n",
    "\\, d\\lambda,\n",
    "$$\n",
    "where\n",
    "$$\n",
    "\\alpha' = \\alpha + n, \\qquad\n",
    "\\beta' = \\beta + \\sum_{i=1}^n x_i.\n",
    "$$\n",
    "This simplifies to\n",
    "$$\n",
    "p(x_{\\mathrm{new}} \\mid x)\n",
    "= \\frac{(\\beta')^{\\alpha'}}{\\Gamma(\\alpha')}\n",
    "\\int_0^\\infty\n",
    "\\lambda^{\\alpha'} e^{-(\\beta' + x_{\\mathrm{new}})\\lambda}\n",
    "\\, d\\lambda.\n",
    "$$\n",
    "Using the Gamma integral,\n",
    "$$\n",
    "\\int_0^\\infty \\lambda^{k-1} e^{-c\\lambda} d\\lambda\n",
    "= \\frac{\\Gamma(k)}{c^k},\n",
    "$$\n",
    "we obtain\n",
    "$$\n",
    "p(x_{\\mathrm{new}} \\mid x)\n",
    "= \\frac{\\alpha' (\\beta')^{\\alpha'}}{(\\beta' + x_{\\mathrm{new}})^{\\alpha'+1}},\n",
    "\\quad x_{\\mathrm{new}} \\ge 0.\n",
    "$$\n",
    "This is a Lomax (Pareto type II) distribution.\n",
    "\n",
    "\\paragraph{MLE vs MAP.}\n",
    "The log-likelihood is\n",
    "$$\n",
    "\\ell(\\lambda) = n \\log \\lambda - \\lambda \\sum_{i=1}^n x_i.\n",
    "$$\n",
    "Maximizing yields the MLE\n",
    "$$\n",
    "\\hat{\\lambda}_{\\mathrm{MLE}}\n",
    "= \\frac{n}{\\sum_{i=1}^n x_i}\n",
    "= \\frac{1}{\\bar{x}}.\n",
    "$$\n",
    "\n",
    "The log-posterior is\n",
    "$$\n",
    "\\log p(\\lambda \\mid x)\n",
    "= (\\alpha+n-1)\\log \\lambda\n",
    "- (\\beta + \\sum_{i=1}^n x_i)\\lambda + C.\n",
    "$$\n",
    "Maximizing gives the MAP estimator\n",
    "$$\n",
    "\\hat{\\lambda}_{\\mathrm{MAP}}\n",
    "= \\frac{\\alpha + n - 1}{\\beta + \\sum_{i=1}^n x_i},\n",
    "\\quad \\alpha + n > 1.\n",
    "$$\n",
    "\n",
    "\\paragraph{Comparison.}\n",
    "$$\n",
    "\\hat{\\lambda}_{\\mathrm{MAP}}\n",
    "\\;\\xrightarrow[n\\to\\infty]{}\\;\n",
    "\\hat{\\lambda}_{\\mathrm{MLE}}.\n",
    "$$\n",
    "For finite samples, the MAP shrinks the estimate toward the prior mean\n",
    "$\\alpha/\\beta$, while the MLE depends only on the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf151c6-edd9-4c68-98d6-7b9ca7e8d6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Numerical optimization of the likelikood \n",
    "\n",
    "We shall now use a numerical method to optimize the likelihoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53d294d-5b01-4e6d-b21d-4d7f9b5263ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [TODO]\n",
    "lam_map_numerical = \n",
    "lam_map_analytic = \n",
    "\n",
    "print(lam_mle_numerical, lam_map_analytic)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
